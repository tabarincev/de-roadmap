## List of content
- Параметра для памяти хранилища
- Особенности PySpark
- Виды памяти
  - Heap
    - Память хранилища (Storage Memory)
    - Память выполнения (Execution Memory)
    - Пользовательская память (User Memory)
    - Зарезервированная память (Reserved Memory)
  - Off-Heap
  - External Process Memory
- Динамическая и статическая аллокация

## Параметра для памяти хранилища
- `memory.fraction` – сегмент от 300 МБ JVM-кучи для выполнения и хранения данных. По умолчанию его значение равно 0,6 – чем оно меньше, тем чаще происходит утечка и вытеснение кэшированных данных.
Эта конфигурация позволяет выделить память для внутренних метаданных и структур пользовательских данных, а также приблизительно оценить размер разреженных необычно больших записей.
- `memory.storageFraction` – часть области `spark.memory.fraction`, объем памяти хранения, невосприимчивый к вытеснению, по умолчанию равный 0,5.
Чем больше это значение, тем меньше оперативной памяти доступно для выполнения, и задачи чаще сохраняются на диск.

## Особенности PySpark
При выполнении пользовательского кода на PySpark используются участки памяти, заданные в конфигурациях `spark.python.worker.memory` и `spark.executor.pyspark.memory`.
При работе с Python-кодом в PySpark исполнитель выполняет два отдельных процесса, которые взаимодействуют друг с другом через мост `Py4J`:
- JVM выполняет часть кода Спарк, связанный с операциями перемешивания, такими как соединение и агрегирование;
- Python, который непосредственно выполняет код пользователя.
Параметр `spark.python.worker.memory` управляет объемом памяти, зарезервированной для каждого процесса worker’а PySpark, за пределами которого он переносится на диск, т.е. этот объем памяти может быть занят объектами, созданными через мост `Py4J` во время Спарк-операций. Если этот параметр не установлен, его значение по умолчанию равно 512 МБ.

Начиная с версии 2.4, параметр `spark.executor.pyspark.memory` контролирует фактическую память процесса worker’а Python, устанавливая предел пространства памяти, который он может адресовать, с помощью свойства `system.RLIMIT_AS`. Если память worker’а Python не установлена ​​через параметр `spark.executor.pyspark.memory`, этот процесс потенциально может занять всю память узла. А, поскольку эта часть памяти не отслеживается диспетчером ресурсов Спарк-кластера, таким как Hadoop YARN, есть риск перепланирования в узле и смены страниц в памяти. В результате возможно замедление работы всех контейнеров YARN на этом узле. Поэтому следует настраивать оба параметра:
- `python.worker.memory` - который ограничивает память в JVM для объектов Python
- `executor.pyspark.memory` - который ограничивает фактическую память процесса Python

## Виды памяти
### Heap
- `Storage Memory` - зарезервированная для кэшированных данных
- `Execution Memory` - используемая структурами данных во время shuffle-операций, при которых данные перемешиваются – т.е. соединение, группировка и агрегирование
- `User Memory` - для хранения структур данных, созданных и управляемых пользовательским кодом
- `Reserved Memory` - для внутренних целей фреймворка

### Off-Heap
Cегмент за пределами JVM, который иногда используется виртуальной машиной Java, например, для метода `intern()`, гарантирующего что все строки с одинаковым содержимым, совместно используют одну и ту же память. Память вне кучи также может использоваться для хранения сериализованных датафреймов и RDD

### External Process Memory
Используется программой на PySpark и SparkR в рамках процессов Python и R вне JVM.

## Динамическая и статическая аллокация
