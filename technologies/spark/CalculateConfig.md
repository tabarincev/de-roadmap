# List of content
- [Количество ядер executor]()
- [Количество executors]()
- [Объем памяти executor]()
- [Память драйвера]()

## Количество ядер executor
> Возьмем для примера dataframe размером 100Гб

- По умолчанию размер одного раздела  —  128 Мб
- 100 Гб = 100 * 1024 Мб = 102400 Мб
- Количество разделов = 102400 / 128 = 800

## Количество executors
> Зная количество ядер, определим, сколько требуется исполнителей

- В среднем на одного исполнителя рекомендуется по 2–5 ядер исполнителя
- Если взять количество ядер исполнителя на одного исполнителя = 4, то общее количество исполнителей = 800 / 4 = 200

> Важно помнить про параметр `sql.shuffle.partitions` = 200, при выделении 400 executors - 200 будут простаивать

## Объем памяти executor
> Общий объем памяти ядра исполнителя по умолчанию равен

- 4 * `Размер одного раздела` = 4 * 128 = 512 МБ
- Общий объем памяти исполнителя = количество ядер * 512 = 4 * 512 = 2 Гб

## Память драйвера
- Зависит от конкретного сценария
- Если запустить `df.collect()`, потребуется `100 Гб` памяти драйвера, ведь драйверу отправятся данные всех исполнителей
- Если вывод просто экспортировать в облако или на диск, то память драйвера в идеале вдвое превысит объем памяти исполнителя = 4 Гб.
