# Spark Roadmap

## Компоненты Spark
- Spark SQL
- Spark Streaming
- Spark MLlib
- Spark GraphX

## Примеры чтения форматов
- Доступные форматы (стр 216)
- Проблемы чтения (стр 215)
- Чтение из базы данных
- Структурированные потоки и дескретизированные
- Spark SQL

## Схема данных
- StructuredSchema

## Преобразования и действия (transforms & actions)
- Transforms
- Actions

## Оптимизатор Catalyst
- explain()
- DAG


## Local vs Cluster vs Interactive mode (стр 153)
- **локальный режим (local mode)** – предпочитаемый разработчиками, так как все работает на одном компьютере и не требует какой-либо специальной конфигурации;
- **режим кластера (cluster mode)** – через диспетчер ресурсов, который развертывает приложение в кластере;
- **интерактивный режим (interactive mode)** – взаимодействие напря- мую или через виртуальную блокнотную среду, которую, вероятнее всего, предпочитают научные работники и экспериментаторы в об- ласти обработки данных.


## Компоненты Spark приложения (стр 169)
![arch](https://f133fde2.rocketcdn.me/wp-content/uploads/2020/07/apache-spark-architecture.png)

- Driver
- Spark Context
- Worker
    - Executor
    - Task
    - Job
- Cluster Manager

## Spark UI
- Информация о кластере
- Работающие приложения
- Завершенные приложения и их состояние

## UDF & UDAF
- Создание udf
- Использование udf с api 
- Использование udf с sql
- Ограничения udf


## Кэширование и копирование данных в контрольных точках
- cache() & persist()
    - уровни хранения данных 
        - MEMORY_ONLY – это уровень по умолчанию. На нем сохраняется RDD, формирующий фрейм данных, как десериализованные объекты Java в виртуальной машине JVM. Если RDD не умещается в памяти, то Spark не будет кешировать разделы, а при необходимости вы- полнит восстановительные вычисления. Пользователь об этом не уведомляется;
        - MEMORY_AND_DISK – аналогичен уровню MEMORY_ONLY, но когда Spark ис- черпывает всю доступную память, он сериализует RDD на диск. Это медленнее, так как диск более медленное устройство, но произво- дительность будет различной в зависимости от класса хранилища на узле (например, NVM-накопители по сравнению с механически- ми накопителями);
        - MEMORY_ONLY_SER – аналогичен уровню MEMORY_ONLY, но объекты Java се- риализуются. Это требует меньшего пространства памяти, но под- готовка потребляет больше процессорного времени;
        - MEMORY_AND_DISK_SER – аналогичен уровню MEMORY_AND_DISK, но с сериа- лизацией;
        - DISK_ONLY – на диск сохраняются разделы RDD, формирующие фрейм данных;
        - OFF_HEAP – поведение аналогично уровню MEMORY_ONLY_SER, но здесь используется память вне кучи. Память вне кучи требует активиза- ции (см. в подразделе 16.1.3 более подробное описание управления памятью).
    - освобождение с unpersist
    - storageLevel()
- checkpoint() (стр 431)
- 5 практик при использовании кэширования
    - Новая переменная \
При кэшировании датафрейма создайте для него новую переменную ```cached_df = df.cache()```. Это позволит всякий раз при вызове ```cached_df.select(…)``` использовать кэшированные данные.
    - unpersist() \
Когда уровень кэширования заполнится, Spark начнет вытеснять данные из памяти, которые использовались давно по стратегии LRU (Least Recently Used). unpersist() позволит контролировать, что именно следует вытеснить. Чем больше места в памяти, тем более эффективно будут работать Spark-приложения.
    - Кэшировать только необходимое \
Перед кешированием убедитесь, что вы кешируете только то, что снова понадобится в SQL-запросах. Например, если один запрос будет использовать (col1, col2, col3), а второй запрос будет использовать (col2, col3, col4), выберите надмножество этих столбцов: ```cached_df = df.select(col1, col2, col3, col4).cache()```. Вызывать ```cached_df= df.cache()``` не стоит, если датафрейм содержит много столбцов, из которых в последующих запросах будет использовать только небольшая часть.
    - Использование UI \
В веб-GUI Spark для каждого кэшированного набора данных можно увидеть, сколько места он занимает в памяти или на диске с детализацией по каждому разделу. 
    ![spark_ui](https://bigdataschool.ru/wp-content/uploads/2020/12/ssqlcah2.png)
    - Накладные расходы \
Кэширование также имеет накладные расходы, связанные с размещением данных в памяти. Поэтому в некоторых случаях повторное вычисление может оказаться быстрее, чем работа с кэшем. Например, если идет обработка запросов на больших наборах данных, хранящихся в колоночных файлах в формате, который поддерживает обрезку столбцов и изменение предикатов, в частности, Parquet. В Parquet запросы выполняются быстро сами по себе: при чтении Spark считывает только метаданные, без сканирования всего набора данных. Для конкретного запроса будет сканироваться только нужный столбец. А при чтении данных из кеша Spark прочитает весь набор данных, что потребует больше времени. Кроме того, в случае большого датасета он просто не умещается полностью в RAM. Часть данных хранится на диске, считывание откуда выполняется намного медленнее, чем из оперативной памяти.

## Delta Lake
- Delta Lake – это база данных (БД) в ядре инфраструктуры Spark
- Необходимость 
- Использование (стр 468)
- Потребление данных из Delta Lake


## Управление ресурсами с помощью YARN, Mesos и K8S (стр 479)
- Выбор правильного менеджера ресурсов (стр 486)

## Безопасность (стр 493)
- Сетевые компоненты
- Использование диска

## Справочник преобразований и действий
- Преобразования
- Действия

## Установка Spark
- Процесс
- Конфигурация

## Perfomance Tunning
https://spark.apache.org/docs/latest/sql-performance-tuning.html#join-strategy-hints-for-sql-queries
- Кэширование
- Опции конфигурации
- Хинты для JOIN
- Хинты для COALESCE
- AQE
  

## Тестирование
- Build-In функции
- Unittest
- PyTest

## Cookbook
